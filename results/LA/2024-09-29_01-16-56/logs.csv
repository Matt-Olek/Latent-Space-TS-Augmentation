dataset,num_classes,num_train_samples,num_test_samples,vae_best_acc,vae_best_f1,classifier_best_acc,classifier_best_f1,classifier_augmented_step_0_best_acc,classifier_augmented_step_0_best_f1,vae_augmented_step_1_best_acc,vae_augmented_step_1_best_f1,classifier_augmented_step_1_best_acc,classifier_augmented_step_1_best_f1,vae_augmented_step_2_best_acc,vae_augmented_step_2_best_f1,classifier_augmented_step_2_best_acc,classifier_augmented_step_2_best_f1,vae_augmented_step_3_best_acc,vae_augmented_step_3_best_f1,classifier_augmented_step_3_best_acc,classifier_augmented_step_3_best_f1,vae_augmented_step_4_best_acc,vae_augmented_step_4_best_f1,classifier_augmented_step_4_best_acc,classifier_augmented_step_4_best_f1,vae_augmented_step_5_best_acc,vae_augmented_step_5_best_f1,classifier_augmented_step_5_best_acc,classifier_augmented_step_5_best_f1,execution_time
FordB,2,3636,810,0.7086420059204102,0.7085282475710688,0.782716049382716,0.7813574003121896,0.7839506172839507,0.783810605927547,0.6987654566764832,0.6980290297937357,0.7753086419753087,0.7744552062133736,0.7111111283302307,0.7108131530124011,0.7728395061728395,0.7719766919959382,0.7123457193374634,0.7116772765395774,0.7765432098765432,0.775437369137165,0.7086420059204102,0.7059149313247675,0.7839506172839507,0.7835519176130354,0.7135802507400513,0.7122046544679339,0.7753086419753087,0.7750824481418813,7972.845149755478
FreezerRegularTrain,2,150,2850,0.9852631688117981,0.9852608061563286,0.9859649122807017,0.9859640759141574,0.9936842105263158,0.9936842105263158,0.9687719941139221,0.9687654656506937,0.9957894736842106,0.995789471610697,0.9628070592880249,0.9627936603648659,0.9929824561403509,0.9929824250375255,0.9617544412612915,0.9617448486695668,0.9929824561403509,0.9929824250375255,0.9554386138916016,0.9553803176102835,0.9912280701754386,0.9912279826982577,0.9761403799057007,0.9761317821208575,0.992280701754386,0.9922805154793517,1059.6115624904633
FreezerSmallTrain,2,28,2850,0.8038596510887146,0.8009427155079512,0.8203508771929825,0.8203040644383319,0.7898245614035088,0.7879068845190474,0.7708772420883179,0.7698865080084392,0.8070175438596491,0.80691399413462,0.7649123072624207,0.7635287089398161,0.8014035087719298,0.8014026285619733,0.7729824781417847,0.7726855550697118,0.8108771929824561,0.8105009010813841,0.7821052670478821,0.7812994164648046,0.7940350877192982,0.7940239045296272,0.7712280750274658,0.7698567022949926,0.8031578947368421,0.8029296109214109,457.3856632709503
"Found array with 1 sample(s) (shape=(1, 50)) while a minimum of 2 is required by GaussianMixture."
"Input X contains NaN.
GaussianMixture does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
"Input X contains NaN.
GaussianMixture does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
"Input X contains NaN.
GaussianMixture does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
"Input X contains NaN.
GaussianMixture does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
"Input X contains NaN.
GaussianMixture does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
GunPoint,2,50,150,0.9666666984558105,0.9666533279978657,0.9933333333333333,0.993333629642799,0.9933333333333333,0.993333629642799,0.9466667175292969,0.9466666666666667,0.9866666666666667,0.9866666666666667,0.9466667175292969,0.9466287137520014,0.9733333333333334,0.9733333333333334,0.9333333373069763,0.9332858921900018,0.9866666666666667,0.9866666666666667,0.9333333373069763,0.9333214793741109,0.9866666666666667,0.9866666666666667,0.9266666769981384,0.9265850945494994,0.98,0.9800008889283968,412.1280417442322
GunPointAgeSpan,2,135,316,0.9778481125831604,0.9778478794251665,0.9936708860759493,0.9936708860759493,0.9810126582278481,0.9810134188472357,0.9272152185440063,0.9268275494075127,0.9841772151898734,0.9841776905627083,0.9145569801330566,0.914453301248308,0.9873417721518988,0.9873422792314905,0.9430379867553711,0.9429557124518613,0.9873417721518988,0.9873402504254493,0.9145569801330566,0.9139285966487436,0.9873417721518988,0.9873402504254493,0.9050633311271667,0.904312015503876,0.9841772151898734,0.9841764227113442,1022.5221924781799
GunPointMaleVersusFemale,2,135,316,1.0,1.0,0.9968354430379747,0.9968359194795887,0.9968354430379747,0.9968349027237305,1.0,1.0,0.9968354430379747,0.9968349027237305,1.0,1.0,0.990506329113924,0.990500890255283,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,668.0302865505219
GunPointOldVersusYoung,2,136,315,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,376.0184397697449
Ham,2,109,105,0.723809540271759,0.722904722904723,0.6857142857142857,0.6788069073783359,0.6476190476190476,0.6398744113029828,0.7714285850524902,0.7704081632653061,0.6761904761904762,0.669012135405578,0.7333333492279053,0.731359649122807,0.6666666666666666,0.6663642137737048,0.7714285850524902,0.7714078374455733,0.6952380952380952,0.6932944606413994,0.7904762029647827,0.7904571843251089,0.6857142857142857,0.6849149397246408,0.7523809671401978,0.7512755102040817,0.6952380952380952,0.6952933858594236,517.3991799354553
HandOutlines,2,1000,370,0.9270270466804504,0.9208969760315462,0.9,0.8985456945225234,0.9054054054054054,0.904437852042461,0.9297297596931458,0.9229166666666666,0.9108108108108108,0.9104220050444224,0.9351351857185364,0.9295707623489102,0.9027027027027027,0.9021881496881498,0.9297297596931458,0.9220699264443797,0.9081081081081082,0.9076221413721414,0.9324324727058411,0.9260112462905639,0.8864864864864865,0.8847073359073359,0.9270270466804504,0.9195205065616163,0.8891891891891892,0.8867906867906867,11152.794976472855
Haptics,5,155,308,0.49025973677635193,0.4544088447502882,0.4772727272727273,0.4550452853553353,0.4675324675324675,0.43525855841444694,0.4707792103290558,0.4664389428372922,0.4935064935064935,0.46522301887208717,0.4675324559211731,0.4417518644821225,0.4805194805194805,0.4302849802771034,0.48051947355270386,0.4652812527337941,0.4577922077922078,0.4091211637003533,0.4935064911842346,0.48547051064056995,0.4707792207792208,0.44535188760457245,0.4610389471054077,0.4358675149409553,0.474025974025974,0.44805947176289357,775.1692402362823
Herring,2,64,64,0.734375,0.7142106645652745,0.59375,0.5690060908084165,0.609375,0.49984761407175204,0.703125,0.6673050615595075,0.625,0.6087662337662337,0.734375,0.7189356755360372,0.609375,0.4768747708104144,0.734375,0.7311588831233011,0.625,0.5092857142857142,0.6875,0.6761133603238867,0.625,0.6142629904559915,0.734375,0.7189356755360372,0.609375,0.49984761407175204,381.2101266384125
HouseTwenty,2,40,119,0.7983193397521973,0.7918367346938775,0.9663865546218487,0.9662836563196706,0.9663865546218487,0.9663865546218487,0.7899159789085388,0.7849967478499675,0.957983193277311,0.9579221267752795,0.7478991746902466,0.7319819819819819,0.957983193277311,0.9579221267752795,0.7647058963775635,0.7642897566496887,0.957983193277311,0.9577804361490154,0.7731092572212219,0.7699248120300752,0.957983193277311,0.9579221267752795,0.7647058963775635,0.7585507246376811,0.9663865546218487,0.9662836563196706,389.8438320159912
InlineSkate,7,100,550,0.3163636326789856,0.3128506901582314,0.41454545454545455,0.4080807360657303,0.4090909090909091,0.3876175356893142,0.2800000011920929,0.27210506917370264,0.4018181818181818,0.3800133316029668,0.27454546093940735,0.27340340004347563,0.3927272727272727,0.389453147170954,0.290909081697464,0.27593782822324714,0.3709090909090909,0.3488223473200273,0.27636364102363586,0.2773773427289991,0.3563636363636364,0.3520335508534181,0.290909081697464,0.28123809408778777,0.32,0.28609681214880106,1414.090977191925
InsectEPGRegularTrain,3,62,249,0.9999999403953552,1.0,1.0,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,0.8313252925872803,0.6163069544364509,1.0,1.0,0.6425702571868896,0.5753846153846154,1.0,1.0,289.8870449066162
InsectEPGSmallTrain,3,17,249,0.9999999403953552,1.0,1.0,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,0.9999999403953552,1.0,1.0,1.0,106.62860631942749
InsectWingbeatSound,11,220,1980,0.6045454740524292,0.5999318083589663,0.5363636363636364,0.5202090643723808,0.5343434343434343,0.5289198513406163,0.6000000238418579,0.5903657163169195,0.5318181818181819,0.5252992181355953,0.6030303239822388,0.5983594360061115,0.5277777777777778,0.5221405583263444,0.5858585834503174,0.5770241023268288,0.5272727272727272,0.5205445166627555,0.5949495434761047,0.5925013023025879,0.5171717171717172,0.505427266682052,0.6161616444587708,0.6162173926352369,0.5181818181818182,0.5112931361717248,696.6579489707947
ItalyPowerDemand,2,67,1029,0.9737609028816223,0.9737584546173238,0.9640427599611273,0.9640414015168075,0.9620991253644315,0.9620991969540617,0.9659863710403442,0.965986266063615,0.9582118561710399,0.9582075932709527,0.9689018726348877,0.9688994673013714,0.9591836734693877,0.9591832879791182,0.967930018901825,0.9679289387564283,0.9601554907677357,0.9601514261420712,0.967930018901825,0.9679289387564283,0.9640427599611273,0.9640414015168075,0.966958224773407,0.9669574316972921,0.9601554907677357,0.9601551144632693,532.8999238014221
LargeKitchenAppliances,3,375,375,0.41066667437553406,0.41413346000501966,0.8453333333333334,0.8438556220135571,0.856,0.8544954247506529,0.46133333444595337,0.4465445421288466,0.8613333333333333,0.8615677308976104,0.46133333444595337,0.4573021737430605,0.8586666666666667,0.8580116671280206,0.46933332085609436,0.4675749574990298,0.8506666666666667,0.8498737859923843,0.46133333444595337,0.4529697820228171,0.8266666666666667,0.8255666420300568,0.46666666865348816,0.44579171038058457,0.8266666666666667,0.8276614729354103,1377.3748795986176
Lightning2,2,60,61,0.7704917788505554,0.7595720720720721,0.7868852459016393,0.785486625694267,0.7704918032786885,0.7704918032786885,0.8196721076965332,0.8165162701668034,0.8032786885245902,0.8013330931363719,0.8032786250114441,0.7966666666666666,0.7704918032786885,0.7708627755794234,0.7868852019309998,0.7831555920153132,0.8032786885245902,0.8013330931363719,0.7868852019309998,0.7750354609929078,0.8032786885245902,0.803596664782363,0.7704917788505554,0.7689393939393939,0.7213114754098361,0.7213114754098361,449.92741537094116
Lightning7,7,70,73,0.698630154132843,0.6862846148560433,0.7123287671232876,0.7091649038296478,0.7397260273972602,0.7400470353967109,0.7260273694992065,0.7170559181837376,0.726027397260274,0.70769672052097,0.698630154132843,0.6941097491628231,0.7671232876712328,0.7623119970632588,0.6849315166473389,0.6715889373784111,0.7671232876712328,0.7673725356729947,0.6849315166473389,0.6462148962148964,0.6712328767123288,0.6720877421482419,0.6575342416763306,0.619947100953966,0.7397260273972602,0.7410346122674889,489.592148065567
